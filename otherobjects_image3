import cv2

#Cargar DNN model y pesos
prototxt = r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\dnn_object_detection\model\MobileNetSSD_deploy.prototxt.txt"
model = r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\dnn_object_detection\model\MobileNetSSD_deploy.caffemodel"

#Etiquetas de las clases
classes = {0:"background", 1:"aeroplane", 2:"bicycle",
          3:"bird", 4:"boat",
          5:"bottle", 6:"bus",
          7:"car", 8:"cat",
          9:"chair", 10:"cow",
          11:"diningtable", 12:"dog",
          13:"horse", 14:"motorbike",
          15:"person", 16:"plant",
          17:"sheep", 18:"sofa",
          19:"train", 20:"tv"}

#Cargar el modelo
net = cv2.dnn.readNetFromCaffe(prototxt, model)

#Lectura de imagen 
image = cv2.imread(r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\images\OtherObjects_Image3.png")
height, width, _ = image.shape
image_resized = cv2.resize(image, (300, 300))

#Crear una blob
blob = cv2.dnn.blobFromImage(image_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5))

#Detección de clases y precisión
net.setInput(blob)
detections = net.forward()
for detection in detections[0][0]:
     print(detection)
     if detection[2] > 0.45:
          label = classes[detection[1]]
          print("Label:", label)
          box = detection[3:7] * [width, height, width, height]
          x_start, y_start, x_end, y_end = int(box[0]), int(box[1]), int(box[2]), int(box[3])
          cv2.rectangle(image, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)
          cv2.putText(image, "Conf: {:.2f}".format(detection[2] * 100), (x_start, y_start - 5), 1, 1.2, (255, 0, 0), 2)
          cv2.putText(image, label, (x_start, y_start - 25), 1, 1.2, (0, 255, 255), 2)

#Imagen por pantalla y finalización de proceso
cv2.imshow("Image with multiple objects", image)
cv2.waitKey(0)
cv2.destroyAllWindows()
