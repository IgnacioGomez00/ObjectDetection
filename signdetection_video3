#Importar librerias necesarias
import cv2

#Video de muestreo .avi
video_entrada = (r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\videos\Video3. Yield - Parking.avi")


#Lectura de imagen y selección de archivos Haar 
cap = cv2.VideoCapture(video_entrada)
#fgbg = cv2.createBackgroundSubtractorMOG2()

#Proporcionan archivos pre - entrenados de las clases a detectar
yield_sign = cv2.CascadeClassifier(r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\XMLs\yield.xml")
parking_sign = cv2.CascadeClassifier(r"C:\Users\ignac\OneDrive\Escritorio\Python\TFG\XMLs\parking.xml")

while cap.isOpened(): 


	#Definir variables y leer el primer frame
	ret, frame = cap.read()
	#fgbg.apply(frame)

	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	color_green = (0,255,0) 
	color_yellow = (0,255,255)

	#Modelo de Haar Cascade
	yield_sign_scaled = yield_sign.detectMultiScale(gray, 1.1, 3, minSize=(30, 30))
	parking_sign_scaled = parking_sign.detectMultiScale(gray, 1.1, 7, minSize=(30, 30))

	#Dibuja rectangulo en las coordenadas del objeto y texto encima del rectangulo identificando su clase

	for (x,y,w,h) in yield_sign_scaled:
		cv2.rectangle(frame, (x,y), (x+w, y+h), color_green, 2)
		cv2.putText(frame, "yield", (x,y-5), 1, 1.2, color_yellow, 2)	

	for (x,y,w,h) in parking_sign_scaled:
		cv2.rectangle(frame, (x,y), (x+w, y+h), color_green, 2)
		cv2.putText(frame, "parking", (x,y-5), 1, 1.2, color_yellow, 2)	

	#Imagen por pantalla
	#cv2.imshow('BackgroundSubtractor',fgbg)
	#cv2.imshow('Gray',gray)
	cv2.imshow("Video Traffic Sign", frame)

	#Finalización del proceso
	if cv2.waitKey(30) == 27:
		break

cap.release()
cv2.destroyAllWindows()
